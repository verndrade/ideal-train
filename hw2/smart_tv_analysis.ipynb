{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart TV Privacy Analysis\n",
    "\n",
    "In this assignment, we will analyze real traces collected from Roku TV and Amazon FireTV to learn more about the behavior of TV channels and whether there's any privacy concern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's read in the data. Given the large size, all data files are stored as \"pickles\" (https://docs.python.org/3/library/pickle.html) to save space. \n",
    "\n",
    "We have four files here: two files for Roku and two files for Amazon FireTV, where \"vanilla\" corresponds to the default configuration, and \"limitad\" corresponds to having the \"limit ad tracking\" option turned on. \n",
    "\n",
    "All four files contain HTTP response traffic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roku data\n",
    "roku_limitad = pd.read_pickle(\"roku-data-limitad_http_resp.pickle\")\n",
    "roku_vanilla = pd.read_pickle(\"roku-data_http_resp.pickle\")\n",
    "\n",
    "# Amazon data\n",
    "amzn_limitad = pd.read_pickle(\"amazon-data-limitad_http_resp.pickle\")\n",
    "amzn_vanilla = pd.read_pickle(\"amazon-data_http_resp.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many records we have in each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roku: 4279 3984\n",
      "Amazon: 8695 8124\n"
     ]
    }
   ],
   "source": [
    "# Roku: number of records\n",
    "print(\"Roku:\", len(roku_vanilla), len(roku_limitad))\n",
    "\n",
    "# Amazon: number of records\n",
    "print(\"Amazon:\", len(amzn_vanilla), len(amzn_limitad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a closer look at the data. The pickle file is read into a \"dataframe\" (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html). You can think of it as a SQL table or spreasheet with columns and rows.\n",
    "\n",
    "For example, let's check out the first five rows in \"roku_vanilla\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_id</th>\n",
       "      <th>data</th>\n",
       "      <th>time</th>\n",
       "      <th>body</th>\n",
       "      <th>location</th>\n",
       "      <th>code</th>\n",
       "      <th>set_cookie</th>\n",
       "      <th>user_agent</th>\n",
       "      <th>ip_src</th>\n",
       "      <th>tcp_srcport</th>\n",
       "      <th>tcp_stream</th>\n",
       "      <th>http2</th>\n",
       "      <th>host_by_dns</th>\n",
       "      <th>domain_by_dns</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>rank</th>\n",
       "      <th>category</th>\n",
       "      <th>status</th>\n",
       "      <th>playback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>01d27b2269223a2263613036333836342d333432612d34...</td>\n",
       "      <td>1556908916.319217000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>54.175.224.52</td>\n",
       "      <td>2350</td>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Prime Video</td>\n",
       "      <td>3</td>\n",
       "      <td>Movies &amp; TV</td>\n",
       "      <td>TERMINATED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td></td>\n",
       "      <td>1556908947.886910000</td>\n",
       "      <td>ï¿½PNG\\r\\n\u001a\\n</td>\n",
       "      <td></td>\n",
       "      <td>200</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>54.230.51.79</td>\n",
       "      <td>80</td>\n",
       "      <td>62</td>\n",
       "      <td>False</td>\n",
       "      <td>g-ecx.images-amazon.com</td>\n",
       "      <td>images-amazon.com</td>\n",
       "      <td>Prime Video</td>\n",
       "      <td>3</td>\n",
       "      <td>Movies &amp; TV</td>\n",
       "      <td>TERMINATED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td></td>\n",
       "      <td>1556908964.537949000</td>\n",
       "      <td>ï¿½PNG\\r\\n\u001a\\n</td>\n",
       "      <td></td>\n",
       "      <td>200</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>54.230.51.130</td>\n",
       "      <td>80</td>\n",
       "      <td>96</td>\n",
       "      <td>False</td>\n",
       "      <td>g-ecx.images-amazon.com</td>\n",
       "      <td>images-amazon.com</td>\n",
       "      <td>Prime Video</td>\n",
       "      <td>3</td>\n",
       "      <td>Movies &amp; TV</td>\n",
       "      <td>TERMINATED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td></td>\n",
       "      <td>1556909007.422930000</td>\n",
       "      <td>ï¿½PNG\\r\\n\u001a\\n</td>\n",
       "      <td></td>\n",
       "      <td>200</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>54.230.51.79</td>\n",
       "      <td>80</td>\n",
       "      <td>146</td>\n",
       "      <td>False</td>\n",
       "      <td>g-ecx.images-amazon.com</td>\n",
       "      <td>images-amazon.com</td>\n",
       "      <td>Prime Video</td>\n",
       "      <td>3</td>\n",
       "      <td>Movies &amp; TV</td>\n",
       "      <td>TERMINATED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td></td>\n",
       "      <td>1556909041.443910000</td>\n",
       "      <td>ï¿½PNG\\r\\n\u001a\\n</td>\n",
       "      <td></td>\n",
       "      <td>200</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>54.230.51.130</td>\n",
       "      <td>80</td>\n",
       "      <td>193</td>\n",
       "      <td>False</td>\n",
       "      <td>g-ecx.images-amazon.com</td>\n",
       "      <td>images-amazon.com</td>\n",
       "      <td>Prime Video</td>\n",
       "      <td>3</td>\n",
       "      <td>Movies &amp; TV</td>\n",
       "      <td>TERMINATED</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channel_id                                               data  \\\n",
       "0         13  01d27b2269223a2263613036333836342d333432612d34...   \n",
       "1         13                                                      \n",
       "2         13                                                      \n",
       "3         13                                                      \n",
       "4         13                                                      \n",
       "\n",
       "                   time           body location code set_cookie user_agent  \\\n",
       "0  1556908916.319217000                                                      \n",
       "1  1556908947.886910000  ï¿½PNG\\r\\n\u001a\\n           200                         \n",
       "2  1556908964.537949000  ï¿½PNG\\r\\n\u001a\\n           200                         \n",
       "3  1556909007.422930000  ï¿½PNG\\r\\n\u001a\\n           200                         \n",
       "4  1556909041.443910000  ï¿½PNG\\r\\n\u001a\\n           200                         \n",
       "\n",
       "          ip_src tcp_srcport tcp_stream  http2              host_by_dns  \\\n",
       "0  54.175.224.52        2350         17  False                            \n",
       "1   54.230.51.79          80         62  False  g-ecx.images-amazon.com   \n",
       "2  54.230.51.130          80         96  False  g-ecx.images-amazon.com   \n",
       "3   54.230.51.79          80        146  False  g-ecx.images-amazon.com   \n",
       "4  54.230.51.130          80        193  False  g-ecx.images-amazon.com   \n",
       "\n",
       "       domain_by_dns channel_name  rank     category      status  playback  \n",
       "0                     Prime Video     3  Movies & TV  TERMINATED     False  \n",
       "1  images-amazon.com  Prime Video     3  Movies & TV  TERMINATED     False  \n",
       "2  images-amazon.com  Prime Video     3  Movies & TV  TERMINATED     False  \n",
       "3  images-amazon.com  Prime Video     3  Movies & TV  TERMINATED     False  \n",
       "4  images-amazon.com  Prime Video     3  Movies & TV  TERMINATED     False  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roku_vanilla.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all five records come from the same channel (channel_id = 13), which is \"Prime Video\" (channel_name). \n",
    "\n",
    "In all five HTTP response records, the channel queries \"images-amazon.com\" domain (domain_by_dns). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: analyze/compare popular domains\n",
    "\n",
    "First, let's find out what are the most popular domains.\n",
    "\n",
    "Complete the following \"get_popular_domains\" function that outputs the **top five domains** that are queried by the most number of **distinct channels**. \\\n",
    "For each domain, output the number of distinct channels that queried it. \n",
    "\n",
    "For example: \\\n",
    "domain1, num_distinct_channels \\\n",
    "domain2, num_distinct_channels \\\n",
    "...\n",
    "\n",
    "Hint: use the **domain_by_dns** column to extract domain, and the **channel_id** column to extract distinct/unique channel.\n",
    "\n",
    "You can either show the output by using \"print\", or output the table format like above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_popular_domains(df):\n",
    "    df = df[[\"domain_by_dns\",\"channel_id\"]]\n",
    "    df = df.groupby('domain_by_dns', as_index=False).nunique()\n",
    "    df = df.sort_values(\"channel_id\", ascending=False)\n",
    "    df.columns = ['domain','num_distinct_channels']\n",
    "    print(df[:5])\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run it and get the top five domains from each file (roku/amazon + vanilla/limitads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    domain  num_distinct_channels\n",
      "0                                              96\n",
      "100               roku.com                     29\n",
      "59                ifood.tv                     14\n",
      "104  scorecardresearch.com                     13\n",
      "39              demdex.net                     11\n"
     ]
    }
   ],
   "source": [
    "# Roku vanilla\n",
    "get_popular_domains(roku_vanilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    domain  num_distinct_channels\n",
      "0                                              97\n",
      "102               roku.com                     26\n",
      "105  scorecardresearch.com                     15\n",
      "62                ifood.tv                     14\n",
      "38              demdex.net                     12\n"
     ]
    }
   ],
   "source": [
    "# Roku w/ limit ads option\n",
    "get_popular_domains(roku_limitad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 domain  num_distinct_channels\n",
      "21           amazon.com                     81\n",
      "0                                           53\n",
      "70      crashlytics.com                     31\n",
      "19       amazon-dss.com                     30\n",
      "18  amazon-adsystem.com                     27\n"
     ]
    }
   ],
   "source": [
    "# Amazon vanilla\n",
    "get_popular_domains(amzn_vanilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 domain  num_distinct_channels\n",
      "19           amazon.com                     76\n",
      "0                                           42\n",
      "65      crashlytics.com                     31\n",
      "17       amazon-dss.com                     20\n",
      "30  app-measurement.com                     19\n"
     ]
    }
   ],
   "source": [
    "# Amazon w/ limit ads option\n",
    "get_popular_domains(amzn_limitad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Describe what you observe from the above results. Do you think the \"limit ads\" option reduce the number of channels that queried domains on Roku and Amazon FireTV? Why or why not?\n",
    "\n",
    "Based on the above results I think that the \"limit ads\" option does not reduce the number of channels that queried domains on Roku devices and does somewhat reduce the number of channels that queried domains on Amazon FireTV devices. When a \"limit ads\" option is selected we would expect the channels that queried domains to decrease. However, when comparing the top five queried domains of Roku vanilla data to the Roku limited data, there are four instances where the number of channels that queried domains increased, clearly showing that the option did not reduce the number of domain queries. When we compare Amazon FireTV vanilla data to the Amazon FireTV limited data, using the \"limit ads\" option reduces number of channels that queried the four of the top five queried domains and kept the number of channels that queried the other top queried domain the same, indicating that the \"limit ads\" option was somewhat limiting the number of channels that queried domains. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: analyze/compare channels\n",
    "\n",
    "Now, let's take a look at the channels. We want to find out which channels queried the most number of distinct domains. \n",
    "\n",
    "Complete the following \"get_channels_with_most_domains\" function that outputs the **top five channel names** that queried the most number of **distinct domains**. \\\n",
    "For each channel name, output its channel category and the number of distinct domains it queried.\n",
    "\n",
    "For example: \\\n",
    "channel1, category, num_distinct_domains \\\n",
    "channel2, category, num_distinct_domains \\\n",
    "...\n",
    "\n",
    "Hint: use the **channel_name** column to extract channel name, and the **category** column to extract channel category.\n",
    "\n",
    "You can either show the output by using \"print\", or output the table format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channels_with_most_domains(df, head=5):\n",
    "    df = df[[\"channel_name\",\"category\", \"domain_by_dns\"]]\n",
    "    df = df.groupby(['channel_name', 'category'], as_index=False).nunique()\n",
    "    df = df.sort_values(\"domain_by_dns\", ascending=False)\n",
    "    df.columns = ['channel', 'category', 'num_distinct_domains']\n",
    "    print(df[:5])\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run it and get the top five channels from each file (roku/amazon + vanilla/limitads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             channel          category  num_distinct_domains\n",
      "20   CopyKat Recipes              Food                    18\n",
      "58          NBC News    News & Weather                    16\n",
      "15             CNNgo    News & Weather                    10\n",
      "55  Models In Motion  Special Interest                    10\n",
      "67       Nickelodeon     Kids & Family                     9\n"
     ]
    }
   ],
   "source": [
    "# Roku vanilla\n",
    "get_channels_with_most_domains(roku_vanilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        channel          category  num_distinct_domains\n",
      "81  Sexy Shorts  Special Interest                    23\n",
      "58     NBC News    News & Weather                    17\n",
      "59   NBC Sports            Sports                    11\n",
      "57          NBA            Sports                    10\n",
      "67  Nickelodeon     Kids & Family                     9\n"
     ]
    }
   ],
   "source": [
    "# Roku w/ limit ads option\n",
    "get_channels_with_most_domains(roku_limitad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              channel     category  \\\n",
      "20  CuriosityStream - Watch Documentaries Online (TV)      Medical   \n",
      "71                                  The CW on Fire TV  Movies & TV   \n",
      "14                                 CBS News - Fire TV         News   \n",
      "48                                           NBC News         News   \n",
      "47                                                NBC  Movies & TV   \n",
      "\n",
      "    num_distinct_domains  \n",
      "20                    40  \n",
      "71                    25  \n",
      "14                    23  \n",
      "48                    21  \n",
      "47                    21  \n"
     ]
    }
   ],
   "source": [
    "# Amazon vanilla\n",
    "get_channels_with_most_domains(amzn_vanilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              channel     category  \\\n",
      "20  CuriosityStream - Watch Documentaries Online (TV)      Medical   \n",
      "47                                                NBC  Movies & TV   \n",
      "71                                  The CW on Fire TV  Movies & TV   \n",
      "15                 CBS Sports Stream &amp; Watch Live       Sports   \n",
      "14                                 CBS News - Fire TV         News   \n",
      "\n",
      "    num_distinct_domains  \n",
      "20                    41  \n",
      "47                    28  \n",
      "71                    20  \n",
      "15                    19  \n",
      "14                    19  \n"
     ]
    }
   ],
   "source": [
    "# Amazon w/ limit ads option\n",
    "get_channels_with_most_domains(amzn_limitad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Describe what you observe from the above results. Do you think the \"limit ads\" option reduce the number of domains queried by channels on Roku and Amazon FireTV? Why or why not?\n",
    "\n",
    "Based on the above results I think that the \"limit ads\" option does not reduce the number of distinct domains queried by channels for either Roku and Amazon FireTV. When looking at the Roku vanilla and Roku limited data, the number of domains queried by the respective top five channels stayed relatively the same, and even increased in some cases. When looking at the Amazon FireTV vanilla and Amazon FireTV limited data, the same behavior was seen where the number of domains queried by the respective top five channels stayed relatively the same, and even increased in some cases. This points to the conclusion that the \"limit ads\" option does not reduce the number of distinct domains queried by channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: analyze \"data leak\"\n",
    "\n",
    "Finally, let's take a deeper look into which data is being collected by the channels. We call it \"data leak\". Every channel may collect different information about the user, e.g., device information and geolocation.\n",
    "\n",
    "Here, we need to use new pickle files with the \"data leak\" information. Let's load the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roku data\n",
    "roku_limitad_leak = pd.read_pickle(\"roku-data-limitad_leak.pickle\")\n",
    "roku_vanilla_leak = pd.read_pickle(\"roku-data_leak.pickle\")\n",
    "\n",
    "# Amazon data\n",
    "amzn_limitad_leak = pd.read_pickle(\"amazon-data-limitad_leak.pickle\")\n",
    "amzn_vanilla_leak = pd.read_pickle(\"amazon-data_leak.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as before, the data is being stored in dataframe format. \n",
    "\n",
    "We will focus on the **id_type** column here. This column indicates *what type of data is being collected and sent by the channel*. \\\n",
    "Let's see what's in the **id_type**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Channel name', 'AD ID', 'Build Number', 'Serial No', 'Zip', 'City']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(roku_vanilla_leak.id_type.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the **id_type** is a bit different in Amazon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Android ID',\n",
       " 'Channel name',\n",
       " 'AD ID',\n",
       " 'Serial No',\n",
       " 'Device name',\n",
       " 'Zip',\n",
       " 'MAC',\n",
       " 'City']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(amzn_vanilla_leak.id_type.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for each of the **id_type** above, we want to know: \n",
    "* How many times it's leaked (i.e., the number of records that have this id_type)\n",
    "* How many channels leak this data (i.e., the number of distinct channels that have this id_type)\n",
    "\n",
    "Complete the following \"analyze_data_leak\" function that does the above. It should output the number of leaks and the number of channels for each **id_type**.\n",
    "\n",
    "For example: \\\n",
    "id_type_1, num_leaks, num_channels \\\n",
    "id_type_2, num_leaks, num_channels \\\n",
    "...\n",
    "\n",
    "You can either show the output by using \"print\", or output the table format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_data_leak(leak_df):\n",
    "    df = leak_df[[\"id_type\",\"channel_id\"]]\n",
    "    df = df.groupby(['id_type'], as_index=False)\n",
    "    df = df.count().merge(df.nunique(), on='id_type')\n",
    "    df.columns = ['id_type','num_leaks','num_channels']\n",
    "    print(df)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run it and find out the data leaks from each file (roku/amazon + vanilla/limitads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id_type  num_leaks  num_channels\n",
      "0         AD ID        655            30\n",
      "1  Build Number        450            34\n",
      "2  Channel name       1747            25\n",
      "3          City          2             2\n",
      "4     Serial No        246            14\n",
      "5           Zip          8             1\n"
     ]
    }
   ],
   "source": [
    "# Roku vanilla\n",
    "analyze_data_leak(roku_vanilla_leak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id_type  num_leaks  num_channels\n",
      "0  Build Number        394            34\n",
      "1  Channel name       1555            26\n",
      "2          City         16             3\n",
      "3     Serial No        213            13\n",
      "4         State          7             1\n",
      "5           Zip         22             2\n"
     ]
    }
   ],
   "source": [
    "# Roku w/ limit ads option\n",
    "analyze_data_leak(roku_limitad_leak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id_type  num_leaks  num_channels\n",
      "0         AD ID        269            35\n",
      "1    Android ID        923            69\n",
      "2  Channel name       1437            20\n",
      "3          City         12             1\n",
      "4   Device name          8             4\n",
      "5           MAC         26             3\n",
      "6     Serial No        201            33\n",
      "7           Zip         21             2\n"
     ]
    }
   ],
   "source": [
    "# Amazon vanilla\n",
    "analyze_data_leak(amzn_vanilla_leak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id_type  num_leaks  num_channels\n",
      "0         AD ID        218            16\n",
      "1    Android ID       1000            65\n",
      "2  Channel name       1419            20\n",
      "3          City         24             1\n",
      "4   Device name          5             2\n",
      "5           MAC         30             3\n",
      "6     Serial No        161            24\n",
      "7           Zip         28             2\n"
     ]
    }
   ],
   "source": [
    "# Amazon w/ limit ads option\n",
    "analyze_data_leak(amzn_limitad_leak)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Describe what you observe from the above results. Does the \"limit ads\" option reduce or eliminate \"data leaks\"? If so, what's the degree of reduction? Please discuss Roku and Amazon FireTV separately. \n",
    "\n",
    "Based on the above results, I think that the \"limit ads\" option substantially reduces \"data leaks\" on Roku devices and does not reduce \"data leaks\" on Amazon FireTV devices overall. When looking at the Roku vanilla and Roku limited data, we can see that the number of leaks for most id type reduce somewhat. The most noticible change on the Roku devices is that the \"AD ID\" id type appears in the Roku vanilla data and does not appear on the Roku limited data, while the \"State\" id type appears in the limited data, but not the vanilla data. However, since so few \"State\" id types (7) appeared to leak in the limited data, it might just be a type that leaks very infrequently and did not leak on the devices captured in the vanilla dataset. However, the \"AD ID\" id type leaked 655 times in the vanilla data, which indicates data of that id type sent frequently, and it is probably intentionally excluded when the \"limit ads\" option is on. When looking at the Amazon FireTV vanilla and Amazon FireTV limited data, we can see that the number of leaks for each id type stay relatively the same for most id types. However, something notable is that the number of leaks for and channels requesting the \"AD ID\" and \"Serial No\" id type is reduced somewhat. \n",
    "\n",
    "Another thing interesting to me is that when the \"limit ads\" option is on for both Roku and Amazon FireTV, then more location data is leaked. This could mean that when these services \"limit ad tracking\" they may just turn off direct consumer targetting using your device information, but still use location data to serve some relevent ads. However, the numbers of leaks for location data is relativly small, so I can not make a definitive conclusion there."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
